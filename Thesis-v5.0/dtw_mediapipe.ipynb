{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from moviepy.editor import *\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from dtaidistance import dtw,dtw_ndim\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# from scipy.spatial.distance import euclidean\n",
    "\n",
    "# from fastdtw import fastdtw as dtw\n",
    "from dtaidistance import dtw_visualisation as dtwvis\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "\n",
    "IN_NAME = ['']\n",
    "OUT_NAME = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening file using tkinter\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "def open_file_dialog(selected_file_label, FILE):\n",
    "\n",
    "    file_path = filedialog.askopenfilename(title=\"Select a File\", filetypes=[(\"Video files\", \"*.mp4\"), (\"All files\", \"*.*\")])\n",
    "    if file_path:\n",
    "        selected_file_label.config(text=f\"Selected File: {file_path}\")\n",
    "        FILE[0] = file_path\n",
    "\n",
    "def Submit(root,input_filename,output_filename):\n",
    "    if input_filename == '' or output_filename == '':\n",
    "        messagebox.showerror(\"Attention\",\"Need to have both student and teacher file\")\n",
    "    else:\n",
    "        root.destroy()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "input_file_label = tk.Label(root, text=\"Student File:\")\n",
    "\n",
    "open_button = tk.Button(root, text=\"Student File\", command= lambda: open_file_dialog(input_file_label,IN_NAME))\n",
    "open_button.pack(padx=20, pady=20)\n",
    "\n",
    "input_file_label.pack()\n",
    "\n",
    "ouput_file_label = tk.Label(root, text=\"Teacher File:\")\n",
    "\n",
    "open_button = tk.Button(root, text=\"Teacher File\", command= lambda: open_file_dialog(ouput_file_label,OUT_NAME))\n",
    "open_button.pack(padx=20, pady=20)\n",
    "\n",
    "ouput_file_label.pack()\n",
    "\n",
    "submit_button = tk.Button(root, text=\"Submit\", command= lambda: Submit(root,IN_NAME[0],OUT_NAME[0]))\n",
    "submit_button.pack(padx=20, pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_NAME = IN_NAME[0]\n",
    "OUT_NAME = OUT_NAME[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of Constant\n",
    "# IN_NAME = fr'..\\media\\Faded_pianella.mp4'\n",
    "# IN_NAME = 'Faded.mp4'\n",
    "# OUT_NAME = fr'..\\media\\output_roseau.mp4'\n",
    "OUTMIX_NAME = fr'..\\media\\outputmix_roseau.mp4'\n",
    "WINDOW_SIZE = 1\n",
    "WINDOWING_SIZE = 5\n",
    "STRIDE = 3\n",
    "POSE_TANGAN = [\n",
    "    'WRIST', \n",
    "    'THUMB_CMP', \n",
    "    'THUMB_MCP', \n",
    "    'THUMB_IP', \n",
    "    'THUMB_TIP', \n",
    "    'INDEX_FINGER_MCP', \n",
    "    'INDEX_FINGER_PIP', \n",
    "    'INDEX_FINGER_DIP', \n",
    "    'INDEX_FINGER_TIP', \n",
    "    'MIDDLE_FINGER_MCP',\n",
    "    'MIDDLE_FINGER_PIP', \n",
    "    'MIDDLE_FINGER_DIP', \n",
    "    'MIDDLE_FINGER_TIP', \n",
    "    'RING_FINGER_MCP', \n",
    "    'RING_FINGER_PIP', \n",
    "    'RING_FINGER_DIP',\n",
    "    'RING_FINGER_TIP', \n",
    "    'PINKY_MCP', \n",
    "    'PINKY_PIP', \n",
    "    'PINKY_DIP', \n",
    "    'PINKY_TIP'\n",
    "]\n",
    "JOINT_LIST = [[2,3,4] , [8,7,6], [12,11,10], [16,15,14], [20,19,18]]\n",
    "JOINT_LIST_NAME = [\n",
    "    [\n",
    "        'THUMB_MCP', \n",
    "        'THUMB_IP', \n",
    "        'THUMB_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'INDEX_FINGER_PIP', \n",
    "        'INDEX_FINGER_DIP', \n",
    "        'INDEX_FINGER_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'MIDDLE_FINGER_PIP', \n",
    "        'MIDDLE_FINGER_DIP', \n",
    "        'MIDDLE_FINGER_TIP'\n",
    "    ],\n",
    "    [ \n",
    "        'RING_FINGER_PIP', \n",
    "        'RING_FINGER_DIP',\n",
    "        'RING_FINGER_TIP'\n",
    "    ],\n",
    "    [ \n",
    "        'PINKY_PIP', \n",
    "        'PINKY_DIP', \n",
    "        'PINKY_TIP'\n",
    "    ]\n",
    "]\n",
    "\n",
    "TWO_JOINTS = [ [0,1], [1,2], [2,3], [3,4], [0,5], [5,9], [5,6], [6,7], [7,8], [9,13], [9,10], [10,11], [11,12], [13,17], [13,14], [14,15], [15,16], [17,18], [18,19], [19,20], [0,17]\n",
    "]\n",
    "\n",
    "TWO_JOINTS_NAME = [\n",
    "    [\n",
    "        'WRIST', \n",
    "        'THUMB_CMP'\n",
    "    ],\n",
    "    [\n",
    "        'THUMB_CMP', \n",
    "        'THUMB_MCP'\n",
    "    ],\n",
    "    [\n",
    "        'THUMB_MCP', \n",
    "        'THUMB_IP'\n",
    "    ],\n",
    "    [\n",
    "        'THUMB_IP', \n",
    "        'THUMB_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'WRIST', \n",
    "        'INDEX_FINGER_MCP'\n",
    "    ],\n",
    "    [\n",
    "        'INDEX_FINGER_MCP', \n",
    "        'INDEX_FINGER_PIP'\n",
    "    ],\n",
    "    [\n",
    "        'INDEX_FINGER_PIP', \n",
    "        'INDEX_FINGER_DIP'\n",
    "    ],\n",
    "    [\n",
    "        'INDEX_FINGER_DIP', \n",
    "        'INDEX_FINGER_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'INDEX_FINGER_MCP', \n",
    "        'MIDDLE_FINGER_MCP'\n",
    "    ],\n",
    "    [\n",
    "        'MIDDLE_FINGER_MCP', \n",
    "        'MIDDLE_FINGER_PIP'\n",
    "    ],\n",
    "    [\n",
    "        'MIDDLE_FINGER_PIP', \n",
    "        'MIDDLE_FINGER_DIP'\n",
    "    ],\n",
    "    [\n",
    "        'MIDDLE_FINGER_DIP', \n",
    "        'MIDDLE_FINGER_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'MIDDLE_FINGER_MCP', \n",
    "        'RING_FINGER_MCP'\n",
    "    ],\n",
    "    [\n",
    "        'RING_FINGER_MCP', \n",
    "        'RING_FINGER_PIP'\n",
    "    ],\n",
    "    [\n",
    "        'RING_FINGER_PIP', \n",
    "        'RING_FINGER_DIP'\n",
    "    ],\n",
    "    [\n",
    "        'RING_FINGER_DIP', \n",
    "        'RING_FINGER_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'RING_FINGER_MCP', \n",
    "        'PINKY_MCP'\n",
    "    ],\n",
    "    [\n",
    "        'PINKY_MCP', \n",
    "        'PINKY_PIP'\n",
    "    ],\n",
    "    [\n",
    "        'PINKY_PIP', \n",
    "        'PINKY_DIP'\n",
    "    ],\n",
    "    [\n",
    "        'PINKY_DIP', \n",
    "        'PINKY_TIP'\n",
    "    ],\n",
    "    [\n",
    "        'WRIST', \n",
    "        'PINKY_MCP'\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING TEACHER EXCEL FILE\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(OUT_NAME)\n",
    "wi = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "hi = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fr = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  \n",
    "output_file = Path(OUT_NAME).stem\n",
    "\n",
    "out = cv2.VideoWriter(fr'..\\media\\output_'+output_file+'.mp4',fourcc, fr, (wi, hi))  \n",
    "pose_tangan = [\n",
    "    'WRIST', \n",
    "    'THUMB_CMP', \n",
    "    'THUMB_MCP', \n",
    "    'THUMB_IP', \n",
    "    'THUMB_TIP', \n",
    "    'INDEX_FINGER_MCP', \n",
    "    'INDEX_FINGER_PIP', \n",
    "    'INDEX_FINGER_DIP', \n",
    "    'INDEX_FINGER_TIP', \n",
    "    'MIDDLE_FINGER_MCP',\n",
    "    'MIDDLE_FINGER_PIP', \n",
    "    'MIDDLE_FINGER_DIP', \n",
    "    'MIDDLE_FINGER_TIP', \n",
    "    'RING_FINGER_MCP', \n",
    "    'RING_FINGER_PIP', \n",
    "    'RING_FINGER_DIP',\n",
    "    'RING_FINGER_TIP', \n",
    "    'PINKY_MCP', \n",
    "    'PINKY_PIP', \n",
    "    'PINKY_DIP', \n",
    "    'PINKY_TIP'\n",
    "]\n",
    "\n",
    "alldata  = []\n",
    "no_frame = []\n",
    "frame_ctr = 0\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "length = total_frame_count/fps\n",
    "\n",
    "pbar = tqdm(total = total_frame_count)\n",
    "count = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    print(\"Analyze teacher Video\")\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        pbar.update(frame_ctr)\n",
    "        # count += fps*5 \n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "\n",
    "        frame_ctr += 1\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image_height, image_width, _ = image.shape\n",
    "        # print(len(image.shape))\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # print(\"Hand \",f'{hand_landmarks.landmark}')\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "                data_tangan  = {}\n",
    "\n",
    "                for i in range(len(pose_tangan)):\n",
    "                    hand_landmarks.landmark[i].x = hand_landmarks.landmark[i].x * image.shape[0]\n",
    "                    hand_landmarks.landmark[i].y = hand_landmarks.landmark[i].y * image.shape[1]\n",
    "                    data_tangan.update(\n",
    "                        {\n",
    "                            pose_tangan[i] : f'{frame_ctr}'+\", \" +f'{hand_landmarks.landmark[i].x}' +\", \" +f'{hand_landmarks.landmark[i].y}'\n",
    "                        }\n",
    "                    )\n",
    "                alldata.append(data_tangan)\n",
    "                no_frame.append(frame_ctr)\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        frame = cv2.flip(image, 0)\n",
    "        # image = cv2.resize(image, (960, 540)) \n",
    "        # cv2.rectangle(image, (20, 60), (120, 160), (0, 255, 0), 2)\n",
    "        # cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "        out.write(image)  \n",
    "        # print(frame_ctr)\n",
    "        if (cv2.waitKey(5) & 0xFF == 27):\n",
    "            break\n",
    "    # print(alldata)\n",
    "    print(\"Print Frame Data\")\n",
    "    df = pd.DataFrame(alldata)\n",
    "    df.to_excel(fr'..\\media\\coordinate_'+output_file+'.xlsx')\n",
    "    # df.to_excel(\"koordinat_faded_roseau.xlsx\")\n",
    "    cap.release()\n",
    "    out.release()  \n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of function\n",
    "def finger_angle_3joints(hand_landmarks,index,joins_lists):\n",
    "    # calculating finger angle\n",
    "    angle_list = []\n",
    "    for joint in joins_lists:\n",
    "        a = np.array([hand_landmarks[index][joint[0]][0], hand_landmarks[index][joint[0]][1]]) # First coord\n",
    "        b = np.array([hand_landmarks[index][joint[1]][0], hand_landmarks[index][joint[1]][1]]) # Second coord\n",
    "        c = np.array([hand_landmarks[index][joint[2]][0], hand_landmarks[index][joint[2]][1]]) # Third coord\n",
    "        \n",
    "        radians = np.arctan2(c[1] - b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "        \n",
    "        if angle > 180.0:\n",
    "            angle = 360-angle\n",
    "        angle_list.append(angle)\n",
    "\n",
    "    return angle_list\n",
    "\n",
    "def finger_angle_2joints(hand_landmarks,index,joins_lists):\n",
    "    # calculating finger angle\n",
    "    angle_list = []\n",
    "    print(len(hand_landmarks))\n",
    "    for joint in joins_lists:\n",
    "        a = np.array([hand_landmarks[index][joint[0]][0], hand_landmarks[index][joint[0]][1]]) # First coord\n",
    "        b = np.array([hand_landmarks[index][joint[1]][0], hand_landmarks[index][joint[1]][1]]) # Second coord\n",
    "        \n",
    "        radians = np.arctan2(b[1] - a[1],b[0]-a[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "        \n",
    "        if angle > 180.0:\n",
    "            angle = 360-angle\n",
    "        angle_list.append(angle)\n",
    "\n",
    "    return angle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FPS = 30\n",
    "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
    "\n",
    "# Note range to display\n",
    "FREQ_MIN = 10\n",
    "FREQ_MAX = 1000\n",
    "\n",
    "# Notes to display\n",
    "TOP_NOTES = 3\n",
    "\n",
    "# Names of the notes\n",
    "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
    "RESOLUTION = (1920, 1080)\n",
    "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
    "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
    "def note_name(n): \n",
    "  global NOTE_NAMES\n",
    "  return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
    "  global FREQ_MAX\n",
    "  global FREQ_MIN\n",
    "  layout = go.Layout(\n",
    "      title=\"frequency spectrum\",\n",
    "      autosize=False,\n",
    "      width=dimensions[0],\n",
    "      height=dimensions[1],\n",
    "      xaxis_title=\"Frequency (note)\",\n",
    "      yaxis_title=\"Magnitude\",\n",
    "      font={'size' : 24}\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(layout=layout,\n",
    "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
    "                  layout_yaxis_range=[0,1]\n",
    "                  )\n",
    "  \n",
    "  fig.add_trace(go.Scatter(\n",
    "      x = xf,\n",
    "      y = p))\n",
    "  \n",
    "  for note in notes:\n",
    "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
    "            text=note[1],\n",
    "            font = {'size' : 48},\n",
    "            showarrow=False)\n",
    "  return fig\n",
    "\n",
    "def extract_sample(audio, frame_number, frame_offset):\n",
    "  global FFT_WINDOW_SIZE\n",
    "  end = frame_number * frame_offset\n",
    "  begin = int(end - FFT_WINDOW_SIZE)\n",
    "\n",
    "  if end == 0:\n",
    "    # We have no audio yet, return all zeros (very beginning)\n",
    "    return np.zeros((np.abs(begin)),dtype=float)\n",
    "  elif begin<0:\n",
    "    # We have some audio, padd with zeros\n",
    "    return np.concatenate([np.zeros((np.abs(begin)),dtype=float),audio[0:end]])\n",
    "  else:\n",
    "    # Usually this happens, return the next sample\n",
    "    return audio[begin:end]\n",
    "\n",
    "def find_top_notes(fft,num, xf):\n",
    "  if np.max(fft.real)<0.001:\n",
    "    return []\n",
    "\n",
    "  lst = [x for x in enumerate(fft.real)]\n",
    "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "  idx = 0\n",
    "  found = []\n",
    "  found_note = set()\n",
    "  while( (idx<len(lst)) and (len(found)<num) ):\n",
    "    f = xf[lst[idx][0]]\n",
    "    y = lst[idx][1]\n",
    "    n = freq_to_number(f)\n",
    "    n0 = int(round(n))\n",
    "    name = note_name(n0)\n",
    "\n",
    "    if name not in found_note:\n",
    "      found_note.add(name)\n",
    "      s = [f,note_name(n0),y]\n",
    "      found.append(s)\n",
    "    idx += 1\n",
    "    \n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teaching file calculation\n",
    "print(\"opening teacher file\")\n",
    "teacher = pd.read_excel(fr'..\\media\\coordinate_'+output_file+'.xlsx')\n",
    "koordinat_guru = []\n",
    "guru = []\n",
    "for i in tqdm(range(len(teacher['WRIST']))):\n",
    "    # frame.append([])\n",
    "    koordinat_guru.append([])\n",
    "    for pose in (POSE_TANGAN):\n",
    "        temp = (teacher[pose][i].split(', '))\n",
    "        koordinat_guru[i].append([eval(temp[1]),eval(temp[2])])\n",
    "        # koordinat_guru[i].append()\n",
    "    guru.append(finger_angle_2joints(koordinat_guru,i,TWO_JOINTS))\n",
    "\n",
    "guru = np.array(guru)\n",
    "# print(teacher['WRIST'][0])\n",
    "# print(koordinat_guru[0])\n",
    "# print(guru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buka buka file dan setting variable\n",
    "cap = cv2.VideoCapture(IN_NAME)\n",
    "cap_teach = cv2.VideoCapture(OUT_NAME)\n",
    "\n",
    "# loading video dsa gfg intro video \n",
    "# clip = VideoFileClip(IN_NAME) \n",
    "  \n",
    "# getting audio from the clip \n",
    "# audio_clip = clip.audio\n",
    "\n",
    "wi = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "hi = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fr = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  \n",
    "out = cv2.VideoWriter(IN_NAME,fourcc, fr, (wi, hi))  \n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "alldata  = []\n",
    "list_d = []\n",
    "frame_ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of function\n",
    "def finger_angle_3joints(hand_landmarks,index,joins_lists):\n",
    "    # calculating finger angle\n",
    "    angle_list = []\n",
    "    for joint in joins_lists:\n",
    "        a = np.array([hand_landmarks[index][joint[0]][0], hand_landmarks[index][joint[0]][1]]) # First coord\n",
    "        b = np.array([hand_landmarks[index][joint[1]][0], hand_landmarks[index][joint[1]][1]]) # Second coord\n",
    "        c = np.array([hand_landmarks[index][joint[2]][0], hand_landmarks[index][joint[2]][1]]) # Third coord\n",
    "        \n",
    "        radians = np.arctan2(c[1] - b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "        \n",
    "        if angle > 180.0:\n",
    "            angle = 360-angle\n",
    "        angle_list.append(angle)\n",
    "\n",
    "    return angle_list\n",
    "\n",
    "def finger_angle_2joints(hand_landmarks,index,joins_lists):\n",
    "    # calculating finger angle\n",
    "    angle_list = []\n",
    "    # print(len(hand_landmarks))\n",
    "    # print(index)\n",
    "    for joint in joins_lists:\n",
    "        a = np.array([hand_landmarks[index][joint[0]][0], hand_landmarks[index][joint[0]][1]]) # First coord\n",
    "        b = np.array([hand_landmarks[index][joint[1]][0], hand_landmarks[index][joint[1]][1]]) # Second coord\n",
    "        \n",
    "        radians = np.arctan2(b[1] - a[1],b[0]-a[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "        \n",
    "        if angle > 180.0:\n",
    "            angle = 360-angle\n",
    "        angle_list.append(angle)\n",
    "\n",
    "    return angle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing mediapipe\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        while tqdm(cap.isOpened()):\n",
    "            success, image = cap.read()\n",
    "            success_teach, image_teach = cap_teach.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                break\n",
    "            if not success_teach:\n",
    "                # print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "            frame_ctr += 1\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "\n",
    "            # Draw the hand annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            image_height, image_width, _ = image.shape\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                        mp_drawing_styles.get_default_hand_connections_style())\n",
    "                    \n",
    "                    # saving hand coordinate\n",
    "                    data_tangan  = {}\n",
    "                    for i in range(len(POSE_TANGAN)):\n",
    "                        hand_landmarks.landmark[i].x = hand_landmarks.landmark[i].x * image.shape[0]\n",
    "                        hand_landmarks.landmark[i].y = hand_landmarks.landmark[i].y * image.shape[1]\n",
    "                        data_tangan.update(\n",
    "                            {\n",
    "                                POSE_TANGAN[i] : f'{frame_ctr}'+\", \" +f'{hand_landmarks.landmark[i].x}' +\", \" +f'{hand_landmarks.landmark[i].y}'\n",
    "                            }\n",
    "                        )\n",
    "                    alldata.append(data_tangan)\n",
    "\n",
    "            # for dtw\n",
    "            if len(alldata) > 0:\n",
    "                # for i in range(0, len(alldata) - WINDOW_SIZE + 1, STRIDE):\n",
    "                i = ((len(alldata) - 1) // WINDOWING_SIZE) * WINDOWING_SIZE\n",
    "                df = pd.DataFrame(alldata[i:i + WINDOWING_SIZE])\n",
    "                koordinat_murid = []\n",
    "                murid = []\n",
    "                for j in range(0, len(df['WRIST'])):\n",
    "                    koordinat_murid.append([])\n",
    "                    for pose in POSE_TANGAN:\n",
    "                        temp = (df[pose][j].split(', '))\n",
    "                        koordinat_murid[j].append([eval(temp[1]),eval(temp[2])])\n",
    "                        # koordinat_murid[j].append()\n",
    "                    murid.append(finger_angle_2joints(koordinat_murid,j,TWO_JOINTS))\n",
    "                murid = np.array(murid)\n",
    "            \n",
    "                # dtw calculate distance with stride and window\n",
    "                windowed_video_landmarks = murid\n",
    "                windowed_excel_landmarks = guru[i:i + WINDOWING_SIZE]\n",
    "                d = dtw_ndim.distance(windowed_excel_landmarks, windowed_video_landmarks, window=WINDOW_SIZE)\n",
    "                list_d.append(d)\n",
    "                # d = sum(list_d) / len(list_d)\n",
    "\n",
    "                # print(\"distance: \"+ str(d))\n",
    "                \n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            frame = cv2.flip(image, 0)\n",
    "            image = cv2.resize(image, (960, 540)) \n",
    "            image_teach = cv2.resize(image_teach, (960, 540)) \n",
    "            canvas = np.zeros((960, 540 * 2, 3),dtype=np.uint8)\n",
    "            canvas[:,:540] = image\n",
    "            canvas[:,540:] = image_teach\n",
    "\n",
    "            cv2.imshow('MediaPipe Hands', canvas)\n",
    "\n",
    "            \n",
    "            # out.write(image)  \n",
    "            if (cv2.waitKey(5) & 0xFF == 27):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "# out.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "print(list_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spit = 100 * 1.07 * np.exp(-0.17 * np.average(list_d))\n",
    "print(spit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtw_mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
